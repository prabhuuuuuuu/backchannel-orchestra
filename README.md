# ğŸ­ Backchannel Orchestra

> Transform solo presentation practice into an interactive experience with AI-powered audience responses

[![murf-ai](https://img.shields.io/badge/Powered%20by-Murf%20Falcon-blue)](https://murf.ai/falcon)
[![AssemblyAI](https://img.shields.io/badge/Speech-AssemblyAI-green)](https://www.assemblyai.com/)
[![FastAPI](https://img.shields.io/badge/Backend-FastAPI-teal)](https://fastapi.tiangolo.com/)

<!-- Demo Video Placeholder: Insert demo video here -->
<!-- ![Demo Video](demo.mp4) or [Watch Demo](demo-link) -->

A real-time AI audience system providing natural vocal backchannels for public speaking practice. Built for the Murf Voice Agent Hackathon using ultra-low latency speech synthesis.

## ğŸŒŸ Key Features

- **Real-Time Vocal Backchannels**: Instant responses ("mm-hmm", "go on", "wow!") triggered by speech patterns via Murf Falcon's 130ms TTS.
- **Emotional Mirror**: Sentiment analysis from AssemblyAI adapts responsesâ€”energetic for positive, supportive for negative, neutral cues for neutral.
- **Orchestra Mode**: Multi-voice crowd simulation with simultaneous reactions.
- **Dynamic Personas**: Switch between Coach (supportive) and Heckler (challenging) modes with prosody controls.

## ğŸ—ï¸ Architecture

<!-- System Architecture Image Placeholder: Insert architecture diagram here -->
<!-- ![System Architecture](architecture.png) -->

**Core Components**:
- **ASR Service**: Real-time speech-to-text with sentiment analysis.
- **Logic Engine**: Rule-based triggering with cooldowns.
- **TTS Service**: Multi-voice generation with prosody.
- **WebSocket Handler**: Bidirectional audio streaming.

## ğŸš€ Setup

### Prerequisites
- Python 3.9+
- Microphone-enabled device
- API Keys: [Murf.ai](https://murf.ai/api), [AssemblyAI](https://www.assemblyai.com/)

### Installation
1. Clone: `git clone https://github.com/yourusername/backchannel-orchestra.git && cd backchannel-orchestra`
2. Virtual env: `python -m venv venv` then activate (Windows: `venv\Scripts\activate`; Mac/Linux: `source venv/bin/activate`).
3. Dependencies: `pip install -r requirements.txt`
4. Config: `cp .env.example .env` and add keys (e.g., `MURF_API_KEY=your_key`).
5. Run backend: `uvicorn app.main:app --reload`
6. Open UI: http://localhost:8000

## ğŸ” API Keys
Store in `.env` (gitignored). Use `.env.example` as template. Rotate keys regularly.

## ğŸ“Š API Details

### WebSocket: `ws://localhost:8000/ws/session`
- **Input**: Raw PCM audio (16kHz, 16-bit, mono).
- **Output**: MP3 chunks + JSON metadata.

**Message Types**:
- Binary: `<MP3_BYTES>`
- JSON: `{"type": "feedback", "text": "mm-hmm", "mode": "coach", "sentiment": "positive"}`

**Voice Commands**:
- "Switch to coach": Supportive mode.
- "Switch to heckler": Challenging mode.

## ğŸ§ª Testing
Run `python test_client.py` to stream mic audio and log backchannels.

## ğŸ“ Structure
```
backchannel-orchestra/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # WebSocket handler
â”‚   â”œâ”€â”€ config.py        # Env config
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ asr_service.py     # AssemblyAI
â”‚   â”‚   â”œâ”€â”€ tts_service.py     # Murf Falcon
â”‚   â”‚   â””â”€â”€ logic_engine.py    # Decision logic
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ audio_utils.py     # Audio helpers
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html       # Web UI
â”‚   â””â”€â”€ client.js        # WebSocket client
â”œâ”€â”€ .env.example         # Key template
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ test_client.py       # Test script
â””â”€â”€ README.md
```

## ğŸ† Hackathon Compliance
- Clear README, demo video, secure keys, tagged `murf-ai`.

## ğŸ› ï¸ Technologies

| Component   | Technology              |
|-------------|-------------------------|
| TTS         | Murf Falcon API         |
| ASR         | AssemblyAI Streaming    |
| Backend     | FastAPI + WebSockets    |
| Frontend    | Vanilla JS + Web Audio  |
| Sentiment   | TextBlob + AssemblyAI   |
| Deployment  | Uvicorn ASGI            |

## ğŸ¯ Use Cases
- Presentation practice with simulated engagement.
- Speech training for confidence.
- Language learning via cues.
- Interview prep under pressure.

## ğŸ”® Enhancements
- Visual avatar with lip-sync.
- Custom phrase training.
- Analytics (pace, fillers, trends).
- Multi-language.
- Hardware integration.

## ğŸ‘¥ Team
Mr. Pranav Prashant Shewale - AI Engineer (ASR/TTS/logic).
Mr. Shourya Agrawal - Full Stack Engineer (UI/streaming).

## ğŸ“„ License
MIT â€“ See [LICENSE](LICENSE).

## ğŸ™ Acknowledgments
- [Murf.ai](https://murf.ai) for Falcon TTS.
- [AssemblyAI](https://www.assemblyai.com) for transcription.
- Murf Hackathon organizers.

**Tags**: `murf-ai` `voice-agent` `tts` `asr` `hackathon` `public-speaking` `fastapi` `websockets`
